model <- glm(virginica ~ ., family = binomial(logit), data=x)
model
summary(model)
pr <- predict(model, x, type="response")
round(pr)
table(actual=x$virginica, predicted=pr>.5)
hist(pr, breaks=20)
hist(pr[x$virginica==TRUE], col="red", breaks=20, add=TRUE)
library(e1071)
modelsvm = svm(Species ~ ., trainData)
svm_pred = predict(modelsvm, testData)
svm_pred
table(svm_pred, testData$Species)
sum(svm_pred==testData$Species)/length(testData$Species)
svm.cpus = svm(perf ~ syct + mmin + mmax + chmax + chmin + cach,
data = cpuTr)
pred.svm.cpu = predict(svm.cpus, cpuTs)
rmse(pred.svm.cpu, cpuTs$perf)
mad(pred.svm.cpu, cpuTs$perf)
iris.sc = iris
iris.sc[,1:4]= scale(iris.sc[,1:4])
set.seed(12345)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData.sc <- iris.sc[ind==1,]
testData.sc <- iris.sc[ind==2,]
library(nnet)
set.seed(123451)
nn = nnet(trainData.sc$Species~ . ,trainData.sc, size=5)
iris.sc = iris
iris.sc[,1:4]= scale(iris.sc[,1:4])
set.seed(12345)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData.sc <- iris.sc[ind==1,]
testData.sc <- iris.sc[ind==2,]
library(nnet)
set.seed(123451)
nn = nnet(trainData.sc$Species~ . ,trainData.sc, size=5)
nn_prev = predict(nn, testData.sc, type = "class")
sum(nn_prev==testData$Species)/length(testData.sc$Species)
nn_prev
p = 1:20
p
inv(p)
p1=20:-1:1
p = seq(20,1,-1)
p1
p1 = seq(20,1,-1)
p1
p = 1:20
p
sum(p)+sum(p1)
p = p+3
p
1p=1/p
pinv=1/p
pinv
gasolina = c(60,55,38,87,65,63,43,44,45,50,78,67)
sum(gasolina)
min(gasolina)
which.min(gasolina)
max(gasolina)
which.max(gasolina)
sum(which(gasolina>med_gas))
med_gas = mean(gasolina)
sum(which(gasolina>med_gas))
med_gas
gasolina>med_gas
sum(gasolina>med_gas)
perc=c(perc,gasolina[i]/sum(gasolina)*100)
med_gas = mean(gasolina)
sum(gasolina>med_gas)
perc=c()
for (i in 0:length(gasolina)){
if (gasolina[i]>med_gas){
perc=c(perc,gasolina[i]/sum(gasolina)*100)
}
med_gas = mean(gasolina)
sum(gasolina>med_gas)
perc=c()
for (i in 0:length(gasolina)){
if (gasolina[i]>med_gas){
perc=c(perc,gasolina[i]/sum(gasolina)*100)
}
}
med_gas = mean(gasolina)
sum(gasolina>med_gas)
perc=c()
for (i in 0:length(gasolina)){
if (gasolina[i]>med_gas){
perc=c(perc,gasolina[i]/sum(gasolina)*100)
}
}
if (gasolina(i)>med_gas){
perc=c(perc,gasolina[i]/sum(gasolina)*100)
}
perc=c(perc,i/sum(gasolina)*100)
med_gas = mean(gasolina)
sum(gasolina>med_gas)
perc=c()
for (i in gasolina){
if (i > med_gas){
perc=c(perc,i/sum(gasolina)*100)
}
}
perc
library(MASS)
data(Cars93)
library(MASS)
data(Cars93)
head(Cars93)
unique(Cars93$Manufacturer)
length(unique(Cars93$Manufacturer))
length(Cars93$Min.Price<10)
length(Cars93$Origin != "USA")
length(Cars93$Origin)
head(Cars93)
View(Cars93)
length(Cars93[Cars93$Min.Price<10])
length(Cars93[Cars93$Min.Price<10,])
length(Cars93[Cars93$Origin != "USA",])
length(Cars93)
length(unique(Cars93$Manufacturer))
Cars93[Cars93$Min.Price<10,]
Cars93[Cars93$Origin != "USA",]
Cars93[Cars93$RPM > 10 & Cars93$RPM > 10,]
37+56
sum(Cars93[Cars93$Min.Price<10,])
sum(Cars93$Min.Price<10,)
sum(Cars93$Min.Price<10)
sum(Cars93$Origin != "USA")
sum(Cars93$RPM > 10 & Cars93$RPM < 20)
table(Cars93$AirBags,Cars93$Type)
data(iris)
f.species = factor(iris$Species)
data(iris)
f.species = factor(iris$Species)
taply(iris$Sepal.Length,f.species,mean)
tapply(iris$Sepal.Length,f.species,mean)
data("CO2")
help(CO2)
dim(CO2)
names(CO2)
length(CO2$Plant)
length(CO2$Plant)
length(CO2$Type)
length(CO2$Treatment)
length(CO2$conc)
length(CO2$uptake)
complete.class(CO2$Plant)
complete.cases(CO2$Plant)
ngth(CO2$Plant)
sum(complete.cases(CO2$Plant))==length(CO2$Plant)
sum(complete.cases(CO2$Plant))==length(CO2$Plant)
sum(complete.cases(CO2$Type))==length(CO2$Type)
sum(complete.cases(CO2$Treatment))==length(CO2$Treatment)
sum(complete.cases(CO2$conc))==length(CO2$conc)
sum(complete.cases(CO2$CO2$uptake))==length(CO2$CO2$uptake)
sum(complete.cases(CO2$uptake))==length(CO2$uptake)
summary(CO2$Plant)
summary(CO2$Type)
summary(CO2$Treatment)
summary(CO2$conc)
summary(CO2$uptake)
CO2[CO2$Treatment == "chilled"]
CO2[CO2$Treatment == "chilled",]
dim(CO2[CO2$Treatment == "chilled",])
CO2$Type
CO2_quebec=CO2[CO2$Type == "Quebec",]
CO2_quebec
namtiz_co2=matrix(CO2$conc,CO2$uptake)
namtiz_co2_conc = CO2$conc
natriz_co2_conc = CO2$conc
natriz_co2_conc
matriz_co2_conc = CO2$conc
matriz_co2 = cbind(matriz_co2_conc,matriz_co2_uptake)
matriz_co2_uptake = CO2$uptake
matriz_co2 = cbind(matriz_co2_conc,matriz_co2_uptake)
row.names(matriz_co2)=CO2$Plant
col.names(matriz_co2)= c("concent","consumo")
rownames(matriz_co2)=CO2$Plant
colnames(matriz_co2)=CO2$Plant
rownames(matriz_co2)=CO2$Plant
colnames(matriz_co2)= c("concent","consumo")
matriz_co2
matriz_co2[Mc3,]
matriz_co2["Mc3",]
matriz_co2["Mc3",:]
matriz_co2["Mc3",]
matriz_co2$"Mc3"
matriz_co2$"Mc3"
matriz_co2["Mc3",]
matriz_co2[rownames(matriz_co2)=="Mc3",]
consumo = matriz_co2[,colnames(matriz_co2)=="consumo"]
CO2[CO2$Plant=="Qc3",]
CO2[CO2$Plant=="Qc3" & CO2$conc == 675,]
CO2%uptake[CO2$Plant=="Qc3" & CO2$conc == 675,]
CO2$uptake[CO2$Plant=="Qc3" & CO2$conc == 675,]
CO2[CO2$Plant=="Qc3" & CO2$conc == 675,"uptake"]
which.max(CO2$uptake)
CO2[which.max(CO2$uptake),]
CO2$Treatment
mean(CO2[CO2$Type=="Mississipi" & CO2$Treatment == "chilled","uptake"])
CO2[CO2$Type=="Mississipi" & CO2$Treatment == "chilled","uptake"]
CO2[CO2$Type=="Mississipi" & CO2$Treatment == "chilled","uptake"]
mean(CO2[CO2$Type=="Mississipi" & CO2$Treatment == "chilled","uptake"])
barplot(table(CO2$type,CO2$uptake))
CO2$type
barplot(table(CO2$Type,CO2$uptake))
table(CO2$Type,CO2$uptake)
plot(CO2$Type,CO2$uptake)
plot(CO2$conc,CO2$uptake)
plot(CO2$conc,CO2$uptake, col= CO2$Treatment)
legend(x="topright", legend = levels(CO2$Treatment), col=c("black","red"))
boxplot(CO2$Type,CO2$uptake)
barplot(CO2$Type,CO2$uptake)
barplot(aggregate(CO2$uptake, list(CO2$Type), mean))
aggregate(CO2$uptake, list(CO2$Type), mean)
barplot(unique(CO2$Type),aggregate(CO2$uptake, list(CO2$Type), mean)[,2])
aggregate(CO2$uptake, list(CO2$Type), mean)[,2]
unique(CO2$Type)
plot(aggregate(CO2$uptake, list(CO2$Type), mean)[,2])
data("chickwts")
type(chickwts)
typeof(chickwts)
complete.cases(chickwts)
summary(chickwts)
chickwts
plot(aggregate(CO2$uptake, list(CO2$Type), mean)[,2])
plot(aggregate(CO2$uptake, list(CO2$Type), mean))
summary(chickwts$fedd)
summary(chickwts$feed)
maen(chickwts$weight)
mean(chickwts$weight)
var(chickwts$weight)
IQR(chickwts$weight)
median(chickwts$weight)
chickwts
aggregate(chickwts$weight, list(weight$feed), mean)
aggregate(chickwts$weight, list(chickwts$feed), mean)
classe=c()
low_median=0.85*median(chickwts$weight)
high_median=1.15*median(chickwts$weight)
for (i in chickwts$weight){
if (i < low_median){classe=c(classe,"low")}
else if (i < high_median){classe=c(classe,"medium")}
else {classe=c(classe,"high")}
}
classe
chickwts_1=cbind(chickwts,classe)
chickwts_1
min(chickwts$weight)
max(chickwts$weight)
hist(chickwts$weight)
hist(chickwts$weight,breaks = c(100,200,300,400,500))
boxplot(chickwts$weight, subset=chickwts$feed)
library(ggplot2)
ggplot(chickwts$weight)
ggplot(chickwt)
ggplot(chickwts)
ggplot(chickwts, aes(chickwts$feed))
boxplot(chickwts$weight)
boxplot(chickwts$weight~chickwts$feed)
library(QSARdata)
library(CRAN)
data(MeltinPoint)
data(MeltingPoint)
data("MeltingPoint")
data(MeltingPoint)
head(MP_Descriptors)
install.packages("QSARdata")
data(MeltingPoint)
head(MP_Descriptors)
library(QSARdata)
data(MeltingPoint)
head(MP_Descriptors)
dim(MP_Descriptors)
dim(MP_Outcome)
MP_Outcome
length(MP_Outcome)
complete.cases(MP_Descriptors)
is.na(MP_Descriptors)
sum(is.na(MP_Descriptors)
)
sum(is.na(MP_Outcome))
sum(is.nan(MP_Descriptors))
sum(is.nan(MP_Outcome))
scale(MP_Outcome)
MP_out=scale(MP_Outcome)
MP_Outcome[order(MP_Outcome)[1:5]]
library(QSARdata)
data(MeltingPoint)
head(MP_Descriptors)
install.packages("mboost")
library(mboost)
data(bodyfat)
library(mboost)
data(bodyfat)
data("bodyfat", package = "TH.data")
na.exclude(bodyfat)
bodyfat_1=na.exclude(bodyfat)
type(bodyfat_1)
typeof(bodyfat_1)
bodyfat_1=data.frame(bodyfat_1[,3:10])
plot(bodyfat_1)
names(bodyfat_1)
pairs(bodyfat_1)
plot(bodyfat_1$waistcirc)
plot(bodyfat_1$waistcirc ~ bodyfat_1$hipcirc)
plot(bodyfat_1$waistcirc ~ bodyfat_1$hipcirc + bodyfat_1$bodyfat_1$hipcirc)
plot(bodyfat_1$waistcirc ~ bodyfat_1$hipcirc + bodyfat_1$elbowbreadth)
plot(bodyfat_1$waistcirc ~ bodyfat_1$hipcirc + bodyfat_1$elbowbreadth)
names(bodyfat_1)
bodyfat
names(bodyfat)
data("bodyfat", package = "TH.data")
bodyfat_1=na.exclude(bodyfat)
typeof(bodyfat_1)
bodyfat_1_1=data.frame(bodyfat_1[,3:10])
pairs(bodyfat_1_1)
plot(mpg ~ hp, data = mtcars, pch = 16, cex = .9)
plot(bodyfat_1_1$elbowbreadth ~ bodyfat_1_1$kneebreadth, data = bodyfat_1, pch = 16, cex = .9)
"create.cvindexes" = function(dataset, k = 5)
{
order = sample(1:nrow(dataset))
res = (order %% k) + 1
}
"run.cv.classif" = function(dataset, k, formula, index.output = ncol(dataset) )
{
require(rpart)
cv.indexes = create.cvindexes(dataset, k)
pred.values = factor(levels=levels(dataset[[index.output]]))
for (i in 1:k)
{
model = rpart(formula, data=dataset[cv.indexes!=i,], method = "class")
tst.indexes = which(cv.indexes==i)
pred.values[tst.indexes] = predict(model, dataset[tst.indexes,], type="class")
}
pred.values
}
cv.indexes.iris = create.cvindexes(iris, 10)
table(cv.indexes.iris)
pred.vals = run.cv.classif(iris, 5, Species~.)
pred.vals
sum(pred.vals == iris$Species) / nrow(iris)
"run.cv.regression" = function(dataset, k, formula)
{
require(rpart)
cv.indexes = create.cvindexes(dataset, k)
pred.values = c()
for (i in 1:k)
{
model = rpart(formula, data=dataset[cv.indexes!=i,])
tst.indexes = which(cv.indexes==i)
pred.values[tst.indexes] = predict(model, dataset[tst.indexes,])
}
pred.values
}
"rmse" = function(obs, pred) sqrt(mean((obs-pred)^2))
"mad" = function(obs, pred) mean(abs(obs-pred))
pred.values.cpus =	run.cv.regression(cpus,	5,	perf ~	syct +	mmin +	mmax +	chmax +
chmin +	cach)
rmse(cpus$perf,	pred.values.cpus)
data(cpus)
library(MASS)
data(cpus)
pred.values.cpus =	run.cv.regression(cpus,	5,	perf ~	syct +	mmin +	mmax +	chmax +
chmin +	cach)
rmse(cpus$perf,	pred.values.cpus)
mad(cpus$perf,	pred.values.cpus)
"run.leave.oneout" = function(dataset, formula, index.output = ncol(dataset))
{
pred.values = factor(levels=levels(dataset[[index.output]]))
for(i in 1:nrow(dataset))
{
model = rpart(formula, data=dataset[-i,], method = "class")
pred.values[i] = predict(model, dataset[i,], type="class")
}
pred.values
}
"pecc" = function(obs, pred) sum(obs == pred) / length(pred)
pred.vals.loo = run.leave.oneout(iris, Species~.)
pecc(iris$Species, pred.vals.loo)
peccs = run.multi.cv(30, iris, 5, Species~.)
mean(peccs)
#Repetições da	validação cruzada
"run.multi.cv" = function(reps, dataset, k, formula, index.output =
ncol(dataset) )
{
pecc.vec = c()
for(r in 1:reps)
{
pred.vals = run.cv.classif(dataset, k, formula, index.output)
pecc.vec[r] = pecc(dataset[[index.output]], pred.vals)
}
pecc.vec
}
peccs = run.multi.cv(30, iris, 5, Species~.)
mean(peccs)
sd(peccs)
t.test(peccs)$conf.int
attr(,"conf.level")
"pensemble"	=	function(p)
{p^3+3*p^2*(1-p)}
pensemble(1/2)
pensemble(1/4)
pensemble(3/4)
library(randomForest)
set.seed(12345)
iris.rf = randomForest(Species ~ ., data=trainData, importance=TRUE)
pred.rf = predict(iris.rf, testData)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
iris.rf = randomForest(Species ~ ., data=trainData, importance=TRUE)
pred.rf = predict(iris.rf, testData)
pecc(pred.rf, testData$Species)
table(pred.rf, testData$Species)
round(importance(iris.rf), 2)
library(caret)
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainDataIris = iris[inTrain,]
testDataIris = iris[-inTrain,]
nrow(trainDataIris)
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
iris_model_lda$resample
preds_iris_lda
#kappa outra estatística
preds_iris_lda = predict(iris_model_lda, testDataIris[,1:4])
preds_iris_lda
confusionMatrix(preds_iris_lda, testDataIris[,5])
iris_lda_cv = train(iris[,1:4], iris[,5], method = "lda", trControl= trainControl(method = "cv"))
iris_lda_cv$results
iris_model_tree = train(trainDataIris[,1:4], trainDataIris[,5],method = "rpart")
iris_model_tree$finalModel
iris_model_tree$results
iris_model_tree$resample
preds_iris_tree = predict(iris_model_tree, testDataIris[,1:4])
confusionMatrix(preds_iris_tree, testDataIris[,5])
cv.ctrl = trainControl("cv", number = 5)
iris_ann = train(Species ~., data = iris,
method = "nnet", tuneLength=5, trControl = cv.ctrl,
preProc = c("center", "scale"))
iris_ann
#decay: forma de regulacao contra overfitting
iris_ann$results
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax",
"chmin", "cach")], cpus[,"perf"], method = "rpart", trControl =
trainControl(method = "repeatedcv", repeats=10))
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax",
"chmin", "cach")], cpus[,"perf"], method = "rpart", trControl =
trainControl(method = "repeatedcv", repeats=10))
model_cv_reg$results
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax",
"chmin", "cach")], cpus[,"perf"], method = "rpart", trControl =
trainControl(method = "repeatedcv", repeats=10))
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax",
"chmin", "cach")], cpus[,"perf"], method = "rpart", trControl =trainControl(method = "repeatedcv", repeats=10))
model_cv_reg$results
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax","chmin", "cach")], cpus[,"perf"], method = "rpart", trControl =trainControl(method = "repeatedcv", repeats=10))
model_cv_reg$results
#10 (Cross validation) * 10 (repeats) * 3 (CP) +1
model_cv_reg$finalModel
model_rf = train(iris[,1:4], iris[,5], method = "rf")
model_rf$results
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(iris[,1:4], iris[,5], sizes=c(1:4),
rfeControl=control)
results
#%%%%%%%%%%5
anyB = grep("^B", ALL$BT)
#%%%%%%%%%%5
data(ALL)
#%%%%%%%%%%5
library(ALL)
library(QSARdata)
library(caret)
set.seed(107)
data(MeltingPoint)
data_f = data.frame(cbind(MP_Descriptors, MP_Outcome))
colnames(data_f)[length(data_f)]="Fusion"
inTrain = createDataPartition(y = data_f$Fusion, p = 0.7, list = F)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainData = data_f[inTrain,]
testData = data_f[-inTrain,]
#acabar isto
data(Puromycin)
wilcox.test(Puromycin$conc~Puromycin$state)
wilcox.test(Puromycin$conc[Puromycin$state=="treated"],Puromycin$conc[Puromycin$state=="untreated"])
Puromycin.new = cbind(Puromycin,Puromycin$conc/Puromycin$rate*1e4)
wilcox.test(Puromycin$conc~Puromycin$state)
wilcox.test(Puromycin$conc[Puromycin$state=="treated"],Puromycin$conc[Puromycin$state=="untreated"])
aggregate(x = Puromycin$conc, by = list(unique.values = Puromycin$state),
FUN = summary)
setwd("E:/UMinho/2semestre/ECBDB/trabalhogrupo")
library(specmine)
load("E:/UMinho/2semestre/ECBDB/trabalhogrupo/.RData")
#LDA
vals=feature_selection(MTBLS654, "Fermentation_days", method = "rfe",  functions=caret::ldaFuncs, validation = "repeatedcv", repeats = 5, number = 10, subsets = 2^(2:4))
res = train_and_predict(MTBLS654_A_bg, MTBLS654_B_bg$data, num.folds = 5, num.repeats = 50,'Fermentation_days', "treebag", "repeatedcv")
MTBLS654_A_bg = subset_x_values(MTBLS654_A, c("glycine", "fructose", "sucrose", "lactate", "mannitol"))
MTBLS654_B_bg = subset_x_values(MTBLS654_B, c("glycine", "fructose", "sucrose", "lactate", "mannitol"))
res = train_and_predict(MTBLS654_A_bg, MTBLS654_B_bg$data, num.folds = 5, num.repeats = 50,'Fermentation_days', "treebag", "repeatedcv")
res$predictions.result
rmse(res$predictions.result[,2], MTBLS654_A_bg$metadata$Fermentation_days)
# [1] 4.278357
mad (res$predictions.result[,2], MTBLS654_A_bg$metadata$Fermentation_days)
#LDA
vals=feature_selection(MTBLS654, "Fermentation_days", method = "rfe",  functions=caret::ldaFuncs, validation = "repeatedcv", repeats = 5, number = 10, subsets = 2^(2:4))
#Naive-Bayes
vals=feature_selection(MTBLS654, "Fermentation_days", method = "rfe",  functions=caret::nbFuncs, validation = "repeatedcv", repeats = 5, number = 10, subsets = 2^(2:4))
